{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15. Shape in CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZtZGxvcP7KdJQVzfXUAp+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Shapes in the Feature Extractors"
      ],
      "metadata": {
        "id": "9Fg-OmM4u7_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1IgrD9kqTfD",
        "outputId": "81a40b76-0c62-4e12-d3cc-a88fd486b251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: (32, 28, 28, 3)\n",
            "\n",
            "W/B : (3, 3, 3, 5)/(5,)\n",
            "After conv1: (32, 28, 28, 5)\n",
            "After conv1_pool: (32, 14, 14, 5)\n",
            "W/B : (3, 3, 5, 5)/(5,)\n",
            "After conv2: (32, 14, 14, 5)\n",
            "After conv2_pool: (32, 7, 7, 5)\n",
            "After flatten: (32, 245)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "N,n_H,n_W,n_c = 32,28,28,3\n",
        "batch_size = 32\n",
        "n_conv_filter =5\n",
        "k_size = 3\n",
        "pool_size, pool_strides = 2,2\n",
        "x = tf.random.normal(shape=(N,n_H,n_W,n_c))\n",
        "\n",
        "#----- feature extractor ----------\n",
        "conv1 = Conv2D(filters = n_conv_filter, kernel_size = k_size,\n",
        "              padding ='same', activation = 'relu')\n",
        "\n",
        "conv1_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides )\n",
        "\n",
        "conv2 = Conv2D(filters = n_conv_filter,kernel_size = k_size,\n",
        "              padding ='same', activation = 'relu')\n",
        "\n",
        "conv2_pool = MaxPooling2D(pool_size = pool_size, strides = pool_strides )\n",
        "# --------- 2개의 conv layer를 만듦\n",
        "\n",
        "flatten = Flatten() \n",
        "\n",
        "print(\"input: {}\\n\".format(x.shape))\n",
        "x = conv1(x)\n",
        "W,B = conv1.get_weights()\n",
        "print(\"W/B : {}/{}\".format(W.shape,B.shape))\n",
        "print(\"After conv1: {}\".format(x.shape))\n",
        "x= conv1_pool(x)\n",
        "print(\"After conv1_pool: {}\".format(x.shape))\n",
        "\n",
        "x = conv2(x)\n",
        "W,B = conv2.get_weights()\n",
        "print(\"W/B : {}/{}\".format(W.shape,B.shape))\n",
        "print(\"After conv2: {}\".format(x.shape))\n",
        "x= conv2_pool(x)\n",
        "print(\"After conv2_pool: {}\".format(x.shape))\n",
        "x = flatten(x) # 이전의 (7,7,5)가 전부 곱해져서 245개가 전부 벡터\n",
        "# 즉, (32, 245) 뜻은 32개의 벡터\n",
        "print(\"After flatten: {}\".format(x.shape))\n",
        "#----- feature extractor end----------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shapes in the Classifier"
      ],
      "metadata": {
        "id": "WDD15L1uu6HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "n_neurons = [50,25,10]\n",
        "\n",
        "dense1 = Dense(units = n_neurons[0], activation='relu')\n",
        "dense2 = Dense(units = n_neurons[1], activation='relu')\n",
        "dense3 = Dense(units = n_neurons[2], activation='softmax') # 마지막 layer는 softmax\n",
        "\n",
        "print(\"input feature : {}\".format(x.shape))\n",
        "x = dense1(x)\n",
        "W,B = dense1.get_weights()\n",
        "print(\"W/B : {}/{}\".format(W.shape,B.shape))\n",
        "print(\"After dense1: {}\\n\".format(x.shape))\n",
        "x = dense2(x)\n",
        "W,B = dense2.get_weights()\n",
        "print(\"W/B : {}/{}\".format(W.shape,B.shape))\n",
        "print(\"After dense2: {}\\n\".format(x.shape))\n",
        "x = dense3(x)\n",
        "W,B = dense3.get_weights()\n",
        "print(\"W/B : {}/{}\".format(W.shape,B.shape))\n",
        "print(\"After dense3: {}\\n\".format(x.shape))\n",
        "# 이런식으로 dense3 에 결과가 나오면 최종적으로 10개를 구분하고 싶다는 이야기이다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z40v5Ouku6P1",
        "outputId": "5de19312-5cd8-4669-883c-8b47e3904a44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input feature : (32, 10)\n",
            "W/B : (10, 50)/(50,)\n",
            "After dense1: (32, 50)\n",
            "\n",
            "W/B : (50, 25)/(25,)\n",
            "After dense2: (32, 25)\n",
            "\n",
            "W/B : (25, 10)/(10,)\n",
            "After dense3: (32, 10)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shapes in the Loss Functions"
      ],
      "metadata": {
        "id": "XeFSMvZUu6Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "y = tf.random.uniform(minval=0, maxval=10,  shape=(32,), dtype=tf.int32)\n",
        "# minval,maxval을 통해 위의 softmax의 prediction을 확인 할 y의 개수를 10개를 만들고, 각각 한개당 shape=(32,1) 형태를 가진다.\n",
        "\n",
        "y = tf.one_hot(y,depth=10)\n",
        "\n",
        "loss_object = CategoricalCrossentropy()\n",
        "\n",
        "loss = loss_object(y,x)\n",
        "\n",
        "print(loss.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCIy8JAfu6Yz",
        "outputId": "b1da8e0b-c9a4-4115-ac24-3c4d27565823"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "()\n",
            "tf.Tensor(2.3227806, shape=(), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}