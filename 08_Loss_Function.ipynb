{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08. Loss Function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPzxUVo6o+nSeV47xAEip+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MSE Calculation"
      ],
      "metadata": {
        "id": "YveiiP9eJt3J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq0XVPs7JjbB",
        "outputId": "5300fd11-0836-4708-d92e-67d1484087e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE(Tensorflow) :  1.7737198\n",
            "MSE(Manual) :  1.7737198\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "loss_object = MeanSquaredError()\n",
        "batch_size = 32\n",
        "predictions = tf.random.normal(shape=(batch_size,1))\n",
        "\n",
        "labels =tf.random.normal(shape=(batch_size,1))\n",
        "\n",
        "mse = loss_object(labels, predictions)\n",
        "mse_manual = tf.reduce_mean(tf.math.pow(labels - predictions,2))\n",
        "print(\"MSE(Tensorflow) : \",mse.numpy())\n",
        "print(\"MSE(Manual) : \",mse_manual.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE with Model/Dataset"
      ],
      "metadata": {
        "id": "OPzV6JXXJujA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 100,5\n",
        "batch_size = 32\n",
        "X = tf.random.normal(shape=(N,n_feature))\n",
        "Y = tf.random.normal(shape=(N,1)) # 마지막 layer의 뉴런 1개\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "model = Dense(units=1, activation='linear')\n",
        "loss_object = MeanSquaredError()\n",
        "\n",
        "for x,y in dataset:\n",
        "  predictions = model(x) # dense layer로 예측값을 뽑고\n",
        "  loss = loss_object(y,predictions) # 실제값과 예측값의 loss를 구한다.\n",
        "\n",
        "  print(loss.numpy())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy8-_U_bJuoV",
        "outputId": "697993bb-899c-43fa-d3ad-9931e7609726"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.7174344\n",
            "3.0824041\n",
            "3.9146416\n",
            "2.7729087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BCE Calculation"
      ],
      "metadata": {
        "id": "3IinmfWSJus2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "predictions = tf.random.uniform(shape=(batch_size,1),minval=0,maxval=1,dtype=tf.float32)\n",
        "\n",
        "labels = tf.random.uniform(shape=(batch_size,1),minval=0,maxval=2,dtype=tf.int32)\n",
        "# binary cross는 마지막에 sigmoid 를 통과하기 때문에 확률로 결과가 나온다\n",
        "# 따라서 출력이 0~1 사이의 값이 될 것이다.\n",
        "\n",
        "loss_object = BinaryCrossentropy()\n",
        "loss = loss_object(labels,predictions)\n",
        "\n",
        "labels = tf.cast(labels, tf.float32)\n",
        "bce_man = -(labels*tf.math.log(predictions)+(1-labels)*tf.math.log(1-predictions))\n",
        "bce_man = tf.reduce_mean(bce_man)\n",
        "\n",
        "print(\"BCE(Tensorflow) : \",loss.numpy())\n",
        "print(\"BCE(Manual) : \",bce_man.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsBY71xBJuyS",
        "outputId": "29fec041-e902-4b11-89ad-ba0729d7592c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCE(Tensorflow) :  0.64613724\n",
            "BCE(Manual) :  0.64613754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BCE with Model/Dataset"
      ],
      "metadata": {
        "id": "YNzx8LvDJviw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 8, 5\n",
        "t_weights = tf.constant([1,2,3,4,5], dtype = tf.float32)\n",
        "t_bias = tf.constant([10], dtype = tf.float32)\n",
        "batch_size = 4\n",
        "\n",
        "X= tf.random.normal(mean=0,stddev=1, shape=(N,n_feature))\n",
        "Y = tf.reduce_sum(t_weights*X, axis=1) + t_bias\n",
        "Y = tf.cast(Y>5, tf.int32)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "model = Dense(units=1, activation='sigmoid')\n",
        "loss_object = BinaryCrossentropy()\n",
        "\n",
        "for x,y in dataset:\n",
        "  prediction = model(x)\n",
        "  loss = loss_object(y,predictions)\n",
        "  print(loss.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlXgd_ouJvo2",
        "outputId": "96933bab-834d-467e-f644-7ab548aab66b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.94514394\n",
            "2.2987292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ULB4-8AoR9db"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}