{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Artificial_Neurons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLLetvq11+9N6FUdEOxVz7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Activation Layers\n",
        "\n"
      ],
      "metadata": {
        "id": "SAcMUb_mVQ8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPCo6hP6VMSM",
        "outputId": "de77f369-669e-4146-c81f-58076a87a5b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x : (1, 5)\n",
            "[[-2.7298937   0.15390831  0.2791101   1.1570961  -0.33311635]]\n",
            "sigmoid(tensorflow): (1, 5)\n",
            "[[0.06123224 0.5384013  0.569328   0.76080465 0.41748255]]\n",
            "tanh(tensorflow): (1, 5)\n",
            "[[-0.9915272   0.15270446  0.27208126  0.82009125 -0.32131818]]\n",
            "relu(tensorflow): (1, 5)\n",
            "[[0.         0.15390831 0.2791101  1.1570961  0.        ]]\n",
            "x : (1, 5)\n",
            "[[-2.7298937   0.15390831  0.2791101   1.1570961  -0.33311635]]\n",
            "sigmoid(manual): (1, 5)\n",
            "[[0.06123227 0.5384013  0.569328   0.76080465 0.41748255]]\n",
            "tanh(manual): (1, 5)\n",
            "[[-0.9915271   0.15270448  0.27208126  0.8200913  -0.3213182 ]]\n",
            "relu(manual): (1, 5)\n",
            "[[0.         0.15390831 0.2791101  1.1570961  0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.math import exp, maximum\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "x= tf.random.normal(shape=(1,5)) #input\n",
        "\n",
        "# imp. activation function\n",
        "\n",
        "sigmoid = Activation('sigmoid') # activation을 sigmoid function으로 만듬\n",
        "tanh = Activation('tanh')\n",
        "relu = Activation('relu')\n",
        "\n",
        "# forward propagation\n",
        "y_sigmoid_tf = sigmoid(x)\n",
        "y_tanh_tf = tanh(x)\n",
        "y_relu_tf = relu(x)\n",
        "\n",
        "\n",
        "print(\"x : {}\\n{}\".format(x.shape, x.numpy()))\n",
        "print(\"sigmoid(tensorflow): {}\\n{}\".format(y_sigmoid_tf.shape, y_sigmoid_tf.numpy()))\n",
        "print(\"tanh(tensorflow): {}\\n{}\".format(y_tanh_tf.shape, y_tanh_tf.numpy()))\n",
        "print(\"relu(tensorflow): {}\\n{}\".format(y_relu_tf.shape, y_relu_tf.numpy()))\n",
        "\n",
        "\n",
        "# forward propagation(manual)\n",
        "y_sigmoid_man = 1/ (1+exp(-x))\n",
        "y_tanh_man = (exp(x)-exp(-x))/(exp(x)+exp(-x))\n",
        "y_relu_man = maximum(x,0)\n",
        "\n",
        "print(\"x : {}\\n{}\".format(x.shape, x.numpy()))\n",
        "print(\"sigmoid(manual): {}\\n{}\".format(y_sigmoid_man.shape, y_sigmoid_man.numpy()))\n",
        "print(\"tanh(manual): {}\\n{}\".format(y_tanh_man.shape, y_tanh_man.numpy()))\n",
        "print(\"relu(manual): {}\\n{}\".format(y_relu_man.shape, y_relu_man.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation in Dense Layer"
      ],
      "metadata": {
        "id": "f88CcC4CY412"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x= tf.random.normal(shape=(1,5)) #input\n",
        "\n",
        "# imp. artificial neurons\n",
        "dense_sigmoid = Dense(units=1, activation='sigmoid') # affine function을 만들고 그 뒤에 바로 activation function이 들어오는것과 같다.\n",
        "# 즉, dense layer의 기능은 affine function과 activation function을 같이 만드는 기능을 한다.\n",
        "dense_tanh = Dense(units=1, activation='tanh')\n",
        "dense_relu = Dense(units=1, activation='relu')\n",
        "\n",
        "# forward propagation\n",
        "y_sigmoid =dense_sigmoid(x)\n",
        "y_tanh = dense_tanh(x)\n",
        "y_relu = dense_relu(x)\n",
        "\n",
        "print(\"AN with sigmoid: {}\\n{}\".format(y_sigmoid.shape, y_sigmoid.numpy()))\n",
        "print(\"AN with tanh: {}\\n{}\".format(y_tanh.shape, y_tanh.numpy()))\n",
        "print(\"AN with relu: {}\\n{}\".format(y_relu.shape, y_relu.numpy())) \n",
        "# numpy로 출력하는건 행렬형태이기 때문에 보기 편하라고 numpy로 출력\n",
        "'''\n",
        "결과에서 shape이 (1,1)인 이유는, input행렬이 (1,5)이니까 weight은 (5,1)이 될것이고\n",
        "따라서 행렬 곱하기 계산하면 1개의 값만 도출된다.\n",
        "'''\n",
        "\n",
        "# forward propagation(manual)\n",
        "print('\\n==========\\n')\n",
        "from tensorflow.math import exp\n",
        "\n",
        "W, b = dense_sigmoid.get_weights()\n",
        "z= tf.linalg.matmul(x,W)+b # affine function 직접 계산\n",
        "a = 1/(1+exp(-z)) # sigmoid의 activation function 계산\n",
        "print('Activation value(Tensorflow):{}\\n{}'.format(y_sigmoid.shape,y_sigmoid.numpy()))\n",
        "print('Activation value(manual):{}\\n{}'.format(a.shape,a.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_syQDHrXXoKO",
        "outputId": "c0933a10-abbe-432a-e632-b08ad3db81a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AN with sigmoid: (1, 1)\n",
            "[[0.3289156]]\n",
            "AN with tanh: (1, 1)\n",
            "[[-0.2029668]]\n",
            "AN with relu: (1, 1)\n",
            "[[0.]]\n",
            "\n",
            "==========\n",
            "\n",
            "Activation value(Tensorflow):(1, 1)\n",
            "[[0.3289156]]\n",
            "Activation value(manual):(1, 1)\n",
            "[[0.3289156]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Artificial Neurons"
      ],
      "metadata": {
        "id": "LVAop-6_cDub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.math import exp, maximum\n",
        "\n",
        "activation = 'sigmoid' # tanh, relu 이여도 가능\n",
        "\n",
        "x= tf.random.uniform(shape=(1,10)) #input\n",
        "\n",
        "dense=Dense(units=1, activation= activation)\n",
        "y_tf = dense(x)\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "y_man = tf.linalg.matmul(x,W) +B\n",
        "if activation == 'sigmoid':\n",
        "  y_man = 1/(1+exp(-y_man))\n",
        "elif activation == 'tanh':\n",
        "  y_man = (exp(y_man)-exp(-y_man))/(exp(y_man)+exp(-y_man))\n",
        "elif activation == 'relu':\n",
        "  y_man = maximum(y_man,0)\n",
        "\n",
        "print(\"Activation : \",activation)\n",
        "print(\"y_tf:{}\\n{}\".format(y_tf.shape,y_tf.numpy()))\n",
        "print(\"y_man:{}\\n{}\".format(y_man.shape,y_man.numpy()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ywl7tY6fabBY",
        "outputId": "c0db6b57-8b89-4d67-f90b-ab6657393a8f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation :  sigmoid\n",
            "y_tf:(1, 1)\n",
            "[[0.50862706]]\n",
            "y_man:(1, 1)\n",
            "[[0.50862706]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of Dense Layers"
      ],
      "metadata": {
        "id": "MGAgLxXoeCtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature =8,10 # set input params\n",
        "x= tf.random.normal(shape=(N,n_feature)) # generate minibatch\n",
        "#print(x.numpy())\n",
        "\n",
        "dense = Dense(units = 1, activation='relu') # imp.\n",
        "y= dense(x)\n",
        "\n",
        "W,B = dense.get_weights()\n",
        "\n",
        "# forward propagation\n",
        "print(\"shape of x: {}\".format(x.shape)) # 8,10\n",
        "print(\"shape of W: {}\".format(W.shape)) # 10,1\n",
        "print(\"shape of B: {}\".format(B.shape)) # bias는 1개"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyvilmH1dp1c",
        "outputId": "cbcfb4b7-6fa1-4c13-f037-ea44b418e4e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.30607805  1.6772068  -2.6307924   0.20952465  0.04917399 -0.3303821\n",
            "  -0.81923145 -0.2614152   0.55739146 -0.50637937]\n",
            " [ 2.0028076   0.42381418  0.8122073  -0.13107726  2.551365   -0.20515145\n",
            "   1.4750204   1.3615882  -0.50693053 -1.4458563 ]\n",
            " [ 0.74342763 -0.65869564 -0.31595582 -0.9145395   1.5734409  -1.2828509\n",
            "   0.50607204  0.63092965 -0.39175978 -0.652068  ]\n",
            " [-1.6127286  -0.02036365  0.78009623  0.10776231  1.168564    0.34379035\n",
            "  -0.76747066 -0.17849961 -1.1429365   0.14772984]\n",
            " [ 0.133406   -1.1381344   1.5330261   1.1800193   0.8581808  -0.5154972\n",
            "  -1.4283302   0.76151985  0.34874728 -0.88398176]\n",
            " [-1.6066247   1.5478613   0.5640773   0.27829385  0.731845   -0.23915376\n",
            "   1.6249925   0.33873317  0.3418506  -0.99893004]\n",
            " [ 0.20091313  1.8056571   0.06696624 -0.38564467 -0.4099732  -0.3566699\n",
            "  -1.3614745   0.28168324  0.11816796  0.04612102]\n",
            " [-0.3407468   1.183966    1.0963446   0.17989278 -1.2252342  -0.16337956\n",
            "   0.99739516  1.5558171   0.5745893  -1.5108483 ]]\n",
            "shape of x: (8, 10)\n",
            "shape of W: (10, 1)\n",
            "shape of B: (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Calculations"
      ],
      "metadata": {
        "id": "mxy2ZOsFeG1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature =8,10 # set input params\n",
        "x= tf.random.normal(shape=(N,n_feature)) # generate minibatch\n",
        "\n",
        "dense = Dense(units = 1, activation='sigmoid') # imp.\n",
        "y_tf = dense(x)\n",
        "\n",
        "# forward propagation(Tensorflow)\n",
        "\n",
        "W,B = dense.get_weights()\n",
        "\n",
        "y_man = tf.linalg.matmul(x,W) +B\n",
        "y_man = 1/(1+exp(-y_man))\n",
        "# result\n",
        "print(\"output(Tensowrflow): \\n\",y_tf.numpy())\n",
        "print(\"output(manual): \\n\",y_man.numpy())\n",
        "print(tf.math.equal(y_tf,y_man)) # 같은지 확인\n",
        "# 그런데 floating point가 달라서 false도 생기긴 함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmKSKFwYeFH1",
        "outputId": "c52b223f-4117-4a08-d1dc-73d6c9303e18"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output(Tensowrflow): \n",
            " [[0.26716083]\n",
            " [0.713917  ]\n",
            " [0.12341836]\n",
            " [0.82812834]\n",
            " [0.5599243 ]\n",
            " [0.3719393 ]\n",
            " [0.23166722]\n",
            " [0.82866704]]\n",
            "output(manual): \n",
            " [[0.26716083]\n",
            " [0.713917  ]\n",
            " [0.12341838]\n",
            " [0.82812834]\n",
            " [0.5599243 ]\n",
            " [0.37193927]\n",
            " [0.23166719]\n",
            " [0.82866704]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zrsahJOHf94R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
